From 62dff146ed7b59eed030eb4c70ed35ea55995ddd Mon Sep 17 00:00:00 2001
From: ordinary jackie <belowzeroiq@proton.me>
Date: Sat, 6 Sep 2025 08:51:16 +0000
Subject: [PATCH 2/2] Revert "ANDROID: 16K: Don't copy data vma for maps/smaps
 output"

This reverts commit 168c322c71e239919b6447a1b22a30d8e6596267.
---
 fs/proc/task_mmu.c               | 31 +++++++++------------
 include/linux/pgsize_migration.h | 16 +++++++++++
 mm/pgsize_migration.c            | 46 +++++++++++++++++++-------------
 3 files changed, 55 insertions(+), 38 deletions(-)

diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c
index 3823dfae52d57..d56513a56baec 100644
--- a/fs/proc/task_mmu.c
+++ b/fs/proc/task_mmu.c
@@ -289,7 +289,7 @@ show_map_vma(struct seq_file *m, struct vm_area_struct *vma)
 	}
 
 	start = vma->vm_start;
-	end = VMA_PAD_START(vma);
+	end = vma->vm_end;
 	show_vma_header_prefix(m, start, end, flags, pgoff, dev, ino);
 
 	/*
@@ -345,12 +345,13 @@ show_map_vma(struct seq_file *m, struct vm_area_struct *vma)
 
 static int show_map(struct seq_file *m, void *v)
 {
-	struct vm_area_struct *vma = v;
+	struct vm_area_struct *pad_vma = get_pad_vma(v);
+	struct vm_area_struct *vma = get_data_vma(v);
 
 	if (vma_pages(vma))
 		show_map_vma(m, vma);
 
-	show_map_pad_vma(vma, m, show_map_vma, false);
+	show_map_pad_vma(vma, pad_vma, m, show_map_vma, false);
 
 	return 0;
 }
@@ -764,10 +765,9 @@ static void smap_gather_stats(struct vm_area_struct *vma,
 		struct mem_size_stats *mss, unsigned long start)
 {
 	const struct mm_walk_ops *ops = &smaps_walk_ops;
-	unsigned long end = VMA_PAD_START(vma);
 
 	/* Invalid start */
-	if (start >= end)
+	if (start >= vma->vm_end)
 		return;
 
 #ifdef CONFIG_SHMEM
@@ -787,15 +787,7 @@ static void smap_gather_stats(struct vm_area_struct *vma,
 		unsigned long shmem_swapped = shmem_swap_usage(vma);
 
 		if (!start && (!shmem_swapped || (vma->vm_flags & VM_SHARED) ||
-					!(vma->vm_flags & VM_WRITE)) &&
-					/*
-					 * Only if we don't have padding can we use the fast path
-					 * shmem_inode_info->swapped for shmem_swapped.
-					 *
-					 * Else we'll walk the page table to calculate
-					 * shmem_swapped, (excluding the padding region).
-					 */
-					end == vma->vm_end) {
+					!(vma->vm_flags & VM_WRITE))) {
 			mss->swap += shmem_swapped;
 		} else {
 			mss->check_shmem_swap = true;
@@ -805,9 +797,9 @@ static void smap_gather_stats(struct vm_area_struct *vma,
 #endif
 	/* mmap_lock is held in m_start */
 	if (!start)
-		walk_page_range(vma->vm_mm, vma->vm_start, end, ops, mss);
+		walk_page_vma(vma, ops, mss);
 	else
-		walk_page_range(vma->vm_mm, start, end, ops, mss);
+		walk_page_range(vma->vm_mm, start, vma->vm_end, ops, mss);
 }
 
 #define SEQ_PUT_DEC(str, val) \
@@ -854,7 +846,8 @@ static void __show_smap(struct seq_file *m, const struct mem_size_stats *mss,
 
 static int show_smap(struct seq_file *m, void *v)
 {
-	struct vm_area_struct *vma = v;
+	struct vm_area_struct *pad_vma = get_pad_vma(v);
+	struct vm_area_struct *vma = get_data_vma(v);
 	struct mem_size_stats mss;
 
 	memset(&mss, 0, sizeof(mss));
@@ -866,7 +859,7 @@ static int show_smap(struct seq_file *m, void *v)
 
 	show_map_vma(m, vma);
 
-	SEQ_PUT_DEC("Size:           ", VMA_PAD_START(vma) - vma->vm_start);
+	SEQ_PUT_DEC("Size:           ", vma->vm_end - vma->vm_start);
 	SEQ_PUT_DEC(" kB\nKernelPageSize: ", vma_kernel_pagesize(vma));
 	SEQ_PUT_DEC(" kB\nMMUPageSize:    ", vma_mmu_pagesize(vma));
 	seq_puts(m, " kB\n");
@@ -881,7 +874,7 @@ static int show_smap(struct seq_file *m, void *v)
 	show_smap_vma_flags(m, vma);
 
 show_pad:
-	show_map_pad_vma(vma, m, show_smap, true);
+	show_map_pad_vma(vma, pad_vma, m, show_smap, true);
 
 	return 0;
 }
diff --git a/include/linux/pgsize_migration.h b/include/linux/pgsize_migration.h
index 359c1807ff1d0..48672dbc84e99 100644
--- a/include/linux/pgsize_migration.h
+++ b/include/linux/pgsize_migration.h
@@ -26,7 +26,12 @@ extern unsigned long vma_pad_pages(struct vm_area_struct *vma);
 extern void madvise_vma_pad_pages(struct vm_area_struct *vma,
 				  unsigned long start, unsigned long end);
 
+extern struct vm_area_struct *get_pad_vma(struct vm_area_struct *vma);
+
+extern struct vm_area_struct *get_data_vma(struct vm_area_struct *vma);
+
 extern void show_map_pad_vma(struct vm_area_struct *vma,
+			     struct vm_area_struct *pad,
 			     struct seq_file *m, void *func, bool smaps);
 
 extern void split_pad_vma(struct vm_area_struct *vma, struct vm_area_struct *new,
@@ -52,7 +57,18 @@ static inline void madvise_vma_pad_pages(struct vm_area_struct *vma,
 {
 }
 
+static inline struct vm_area_struct *get_pad_vma(struct vm_area_struct *vma)
+{
+	return NULL;
+}
+
+static inline struct vm_area_struct *get_data_vma(struct vm_area_struct *vma)
+{
+	return vma;
+}
+
 static inline void show_map_pad_vma(struct vm_area_struct *vma,
+				    struct vm_area_struct *pad,
 				    struct seq_file *m, void *func, bool smaps)
 {
 }
diff --git a/mm/pgsize_migration.c b/mm/pgsize_migration.c
index b2b8e70739c2c..c24c1e9f9ccd3 100644
--- a/mm/pgsize_migration.c
+++ b/mm/pgsize_migration.c
@@ -257,10 +257,10 @@ static const struct vm_operations_struct pad_vma_ops = {
 };
 
 /*
- * Returns a new VMA representing the padding in @vma;
- * returns NULL if no padding in @vma or allocation failed.
+ * Returns a new VMA representing the padding in @vma, if no padding
+ * in @vma returns NULL.
  */
-static struct vm_area_struct *get_pad_vma(struct vm_area_struct *vma)
+struct vm_area_struct *get_pad_vma(struct vm_area_struct *vma)
 {
 	struct vm_area_struct *pad;
 
@@ -268,10 +268,6 @@ static struct vm_area_struct *get_pad_vma(struct vm_area_struct *vma)
 		return NULL;
 
 	pad = kzalloc(sizeof(struct vm_area_struct), GFP_KERNEL);
-	if (!pad) {
-		pr_warn("Page size migration: Failed to allocate padding VMA");
-		return NULL;
-	}
 
 	*pad = *vma;
 
@@ -293,14 +289,34 @@ static struct vm_area_struct *get_pad_vma(struct vm_area_struct *vma)
 	return pad;
 }
 
+/*
+ * Returns a new VMA exclusing the padding from @vma; if no padding in
+ * @vma returns @vma.
+ */
+struct vm_area_struct *get_data_vma(struct vm_area_struct *vma)
+{
+	struct vm_area_struct *data;
+
+	if (!is_pgsize_migration_enabled() || !(vma->vm_flags & VM_PAD_MASK))
+		return vma;
+
+	data = kzalloc(sizeof(struct vm_area_struct), GFP_KERNEL);
+
+	*data = *vma;
+
+	/* Adjust the end to the start of the padding section */
+	data->vm_end = VMA_PAD_START(data);
+
+	return data;
+}
+
 /*
  * Calls the show_pad_vma_fn on the @pad VMA, and frees the copies of @vma
  * and @pad.
  */
-void show_map_pad_vma(struct vm_area_struct *vma, struct seq_file *m,
-		      void *func, bool smaps)
+void show_map_pad_vma(struct vm_area_struct *vma, struct vm_area_struct *pad,
+		      struct seq_file *m, void *func, bool smaps)
 {
-	struct vm_area_struct *pad = get_pad_vma(vma);
 	if (!pad)
 		return;
 
@@ -316,21 +332,13 @@ void show_map_pad_vma(struct vm_area_struct *vma, struct seq_file *m,
 	 */
 	BUG_ON(!vma);
 
-	/* The pad VMA should be anonymous. */
-	BUG_ON(pad->vm_file);
-
-	/* The pad VMA should be PROT_NONE. */
-	BUG_ON(pad->vm_flags & (VM_READ|VM_WRITE|VM_EXEC));
-
-	/* The pad VMA itself cannot have padding; infinite recursion */
-	BUG_ON(pad->vm_flags & VM_PAD_MASK);
-
 	if (smaps)
 		((show_pad_smaps_fn)func)(m, pad);
 	else
 		((show_pad_maps_fn)func)(m, pad);
 
 	kfree(pad);
+	kfree(vma);
 }
 
 /*
-- 
2.49.0

